{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Parquet Example\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4519891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Parquet file path\n",
    "parquet_file_path = '/Users/trevor/trevorscholz1/spotify/music-feed-examples/python_example/apple_music_songs/115_part_song_2025-05-14T16-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8372d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Read the Parquet file\n",
    "df = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c35826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.limit(1000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434dcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[['nameDefault','parentalAdvisoryType','primaryArtists','album','releaseDate','durationInMillis','genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eddbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dirty):\n",
    "    dirty = str(dirty)\n",
    "    clean = dirty.split('name=\\'')[-1].split('\\')')[0]\n",
    "    return clean\n",
    "\n",
    "def get_date(dirty):\n",
    "    clean = dirty['default']\n",
    "    return clean\n",
    "\n",
    "def get_genres(dirty):\n",
    "    clean = []\n",
    "    for genre in dirty:\n",
    "        clean_genre = str(genre).split('name=\\'')[-1].split('\\'')[0]\n",
    "        clean.append(clean_genre)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce501a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['primaryArtists'] = train['primaryArtists'].apply(clean_data)\n",
    "train['album'] = train['album'].apply(clean_data)\n",
    "train['releaseDate'] = train['releaseDate'].apply(get_date)\n",
    "train['genres'] = train['genres'].apply(get_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19978656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Prepare data\n",
    "\n",
    "# Convert releaseDate to datetime, extract features like year, month\n",
    "train['releaseDate'] = pd.to_datetime(train['releaseDate'])\n",
    "train['year'] = train['releaseDate'].dt.year\n",
    "train['month'] = train['releaseDate'].dt.month\n",
    "\n",
    "le_advisory = LabelEncoder()\n",
    "train['parentalAdvisory_encoded'] = le_advisory.fit_transform(train['parentalAdvisoryType'])\n",
    "\n",
    "# Encode primaryArtists (optional, can be high cardinality)\n",
    "le_artist = LabelEncoder()\n",
    "train['artist_encoded'] = le_artist.fit_transform(train['primaryArtists'])\n",
    "\n",
    "# Genres: Use MultiLabelBinarizer (since genres is a list)\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(train['genres'])\n",
    "\n",
    "# Put it all together into a feature matrix\n",
    "features = pd.DataFrame({\n",
    "    'durationInMillis': train['durationInMillis'],\n",
    "    'year': train['year'],\n",
    "    'month': train['month'],\n",
    "    'parentalAdvisory': train['parentalAdvisory_encoded'],\n",
    "    'artist': train['artist_encoded']\n",
    "})\n",
    "\n",
    "# Add the genre one-hot columns\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_)\n",
    "features = pd.concat([features, genres_df], axis=1)\n",
    "\n",
    "# Optional: scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "# 2. Run KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)  # choose clusters number as you see fit\n",
    "train['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Now your train dataframe has a 'cluster' column showing cluster assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bedbfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
